#### 如何理解机器学习？	 **[E]**

简单来说，让**机器**去**学习**。**机器**也就是计算机，而**学习**的本质就是模型的训练过程。通过机器学习，可以使得计算机利用模型算法来提取数据的内在规律，并可以通过训练后的模型进行预测。

#### 如何理解机器学习、人工智能、深度学习三者之间的关系	 **[E]**

在机器学习、人工智能和深度学习这三种需求技术之间很容易混淆。这三种技术虽然彼此之间略有不同，但却是相互关联的。深度学习是机器学习的一个子集，而机器学习是人工智能的一个子集。由于某些术语和技术在这些技术中可能重叠，因此很容易混淆它们。

- **机器学习：**机器学习涉及各种统计和深度学习技术，这些技术允许机器利用他们过去的经验并更好地执行特定任务，而无需进行监控。
- **人工智能：**人工智能使用大量机器学习和深度学习技术，使计算机系统能够使用具有逻辑和规则的类人智能执行任务。
- **深度学习：**深度学习包含多种神经网络算法，使模型能够自我学习并执行各种业务任务，包括图像和语音识别。

#### 机器学习都有哪些类型？	 **[E]**

- **监督学习：**在监督机器学习中，模型根据过去或标记的数据做出预测或决策。带标签的数据是指给定标签或标签的数据集，因此更有意义。
- **无监督学习：**在无监督学习中，没有标记数据。模型可以识别输入数据中的模式、异常和关系
- **强化学习：**使用强化学习，模型可以根据之前的动作获得的奖励进行学习。考虑一个Agent正在工作的环境。给Agent一个要实现的目标。每次Agent对目标采取一些行动时，都会得到积极的反馈。而且，如果所采取的行动偏离了目标，那么Agent就会得到负面反馈。 通过多次循环使得Agent能过选择最优解
- **主动学习：**通过机器学习的方法获取到那些比较**“难”**分类的样本数据，让人工再次确认和审核，然后将人工标注得到的数据再次使用有监督学习模型或者半监督学习模型进行训练，逐步提升模型的效果，将人工经验融入机器学习的模型中。

#### 经验风险最小化	[E]

经验风险最小化是统计学习理论的一项原则，通过经验风险最小化可以为机器学习算法性能提供理论基础。

##### 如何理解经验风险最小化的"风险"？

可以认为其是算法模型预测结果与实际结果的差异

##### 为什么它是"经验性"？

经验风险最小化(ERM)：**对训练集中的所有样本损失均值**（经验误差）的最小化。因此，经验风险是局部最优的现实情况。假设所有数据集包括训练集和预测集合，算法的最终目标是最小化所有数据集的最小差异（“风险”），但是最小话整体的“期望风险最小化”太难了，所以只在训练集上训练的风险称之为经验风险。训练集可以当作经验数据

##### 如何将这种风险降到最低？

通常，无法计算风险$R(h)$，因为学习算法不知道分布$P(X,Y)$（这种情况称为无知学习)。但是，我们可以通过对训练集上的损失函数取平均值来计算一个近似值，称为经验风险：
$$
R_{\mathrm{emp}}(h)=\frac{1}{n} \sum_{i=1}^{n} L\left(h\left(x_{i}\right), y_{i}\right)
$$
经验风险最小化原理指出学习算法应选择一个假设$\hat{h}$经验风险降到最低：
$$
\hat{h}=\arg \min _{h \in \mathcal{H}} R_{\mathrm{emp}}(h)
$$
同样，算法的训练过程就是解决上述的优化问题。

#### 为什么分类问题和回归问题不同？	[E]

分类和回归的区别在于输出变量的类型。

- **定量输出**称为回归，或者说是连续变量预测； 
- **定性输出**称为分类，或者说是离散变量预测。

回归问题是用来预测一个值，例如房价、价格等等；分类问题是将某个事物打上标签，通常是离散值

本质上来讲，分类模型和回归模型都是要建立映射关系；实际操作中也可以将回归问题和分类问题相互转化，例如分类模型可以将回归模型输出的离散化，回归模型也可将分类模型的输出连续化；



#### 参数方法与非参数方法？频率派和贝叶斯派？	[M]

**参数方法**表示参数固定，不随数据点的变化而变化；（频率派）
**非参数方法**并不意味着没有参数，而是说，参数的数目随数据点而变化。（贝叶斯派）

频率学派和贝叶斯学派对世界的认知有本质不同：**频率学派认为世界是确定的（数据服从一个分布，需要主找到该分布的参数），有一个本体，这个本体的真值是不变的，我们的目标就是要找到这个真值或真值所在的范围**；

而**贝叶斯学派认为世界是不确定的（数据不确定，通过后验概率做调整），人们对世界先有一个预判，而后通过观测数据对这个预判做调整，我们的目标是要找到最优的描述这个世界的概率分布。**

**MLE - 最大似然估计**

假设数据 ![[公式]](https://www.zhihu.com/equation?tex=x_1%2C+x_2%2C+...%2C+x_n+) 是i.i.d.的一组抽样，![[公式]](https://www.zhihu.com/equation?tex=X+%3D+%28x_1%2C+x_2%2C+...%2C+x_n%29) 。其中i.i.d.表示Independent and identical distribution，独立同分布。那么MLE对 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta) 的估计方法可以如下推导：

![[公式]](https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%2A%7D+%5Chat%7B%5Ctheta%7D_%5Ctext%7BMLE%7D+%26%3D+%5Carg+%5Cmax+P%28X%3B+%5Ctheta%29+%5C%5C+%26%3D+%5Carg+%5Cmax+P%28x_1%3B+%5Ctheta%29+P%28x_2%3B+%5Ctheta%29+%5Ccdot%5Ccdot%5Ccdot%5Ccdot+P%28x_n%3B%5Ctheta%29+%5C%5C+%26+%3D+%5Carg+%5Cmax%5Clog+%5Cprod_%7Bi%3D1%7D%5E%7Bn%7D+P%28x_i%3B+%5Ctheta%29+%5C%5C+%26%3D+%5Carg+%5Cmax+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Clog+P%28x_i%3B+%5Ctheta%29+%5C%5C+%26%3D+%5Carg+%5Cmin+-+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Clog+P%28x_i%3B+%5Ctheta%29+%5Cend%7Balign%2A%7D)

**MAP - 最大后验估计**

同样的，假设数据 ![[公式]](https://www.zhihu.com/equation?tex=x_1%2C+x_2%2C+...%2C+x_n+) 是i.i.d.的一组抽样，![[公式]](https://www.zhihu.com/equation?tex=X+%3D+%28x_1%2C+x_2%2C+...%2C+x_n%29) 。那么MAP对 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta) 的估计方法可以如下推导：

![[公式]](https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%2A%7D+%5Chat%7B%5Ctheta%7D_%5Ctext%7BMAP%7D+%26%3D+%5Carg+%5Cmax+P%28%5Ctheta+%7C+X%29+%5C%5C+%26%3D+%5Carg+%5Cmin+-%5Clog+P%28%5Ctheta+%7C+X%29+%5C%5C+%26+%3D+%5Carg+%5Cmin+-%5Clog+P%28X%7C%5Ctheta%29+-+%5Clog+P%28%5Ctheta%29+%2B+%5Clog+P%28X%29+%5C%5C+%26%3D+%5Carg+%5Cmin+-%5Clog+P%28X%7C%5Ctheta+%29+-+%5Clog+P%28%5Ctheta%29+%5Cend%7Balign%2A%7D)

**重点：**

**只有频率派才有过拟合的**，并且通过正则化项和集成的方式来缓解；贝叶斯派引入了先验分布等价于对模型复杂度有了约束。

在MAP中使用一个“高斯分布的先验” **等价于** 在MLE中采用 “L2正则化”；

在MAP中使用一个“拉普拉斯分布的先验” **等价于** 在MLE中采用 “ L1正则化”。



####  为什么 ML 模型的性能在生产中会下降/退化？ [M]

> **概念漂移:** 表示模型试图预测的目标变量的统计特性随着时间以不可预见的方式发生变化。这导致了一些问题，因为随着时间的推移，预测的准确性会降低。

会发生概念漂移。一般来说，我们对数据的解释随时间而变化，而数据的一般分布则没有变化。这导致最终用户将模型预测解释为随着时间的推移，对相同/相似数据的预测已经恶化。数据和概念都可能同时漂移，使问题更加棘手。

##### **如何防止模型退化？**

#### 为什么 L1 正则化倾向于导致稀疏，而 L2 正则化将权重推向接近 0？[M]

#### 为什么集成独立训练的模型通常会提高性能？[M]

#### 模型在测试集上表现非常好，但在生产中表现不佳，猜测原因是什么？[M]

##### 如何验证你的猜想？	[M]

##### 假设猜想是正确的，如何解决？	[H]